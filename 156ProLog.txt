
We downloaded the datafile house-votes-84.data.txt from the webpage 
https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/

Using bash shell scripting, we changed democrat to 1, republican to -1,
y to 1, n to -1, ? to 0 and saved the resulting datafile as votes.csv

sed 's/democrat/1/;s/republican/-1/;s/y/1/g;s/n/-1/g;s/?/0/g' <house-votes-84.data.txt >votes.csv

Using a python script we generated a training dataset consisting of 80% of the original data,
i.e. 348 out of 435 voting patterns of the members of congress, and used the remaining 20% of the 
data as the testing dataset.

The python script is as follows:
#-----------------------#
#!/usr/local/bin/python
import numpy as np
import random

filename="156Project/votes.csv"
array=np.genfromtxt(filename,dtype="int",delimiter=",")

population_size=array.shape[0]
population_indices=np.arange(population_size)
training_indices=random.sample(population_indices,int(population_size*0.8))
testing_indices=list(set(population_indices)-set(training_indices))

training_data=array[training_indices,:]
testing_data=array[testing_indices,:]
np.savetxt("testing_data.csv",testing_data,delimiter=",",fmt="%d")
np.savetxt("training_data.csv",training_data,delimiter=",",fmt="%d")

#-----------------------#

%Adaboost

training_data=csvread('training_data.csv')
testing_data=csvread('testing_data.csv')

democrat_indices=find(training_data(:,1)==1);
republican_indices=find(training_data(:,1)==-1);
X0=training_data(democrat_indices,:);
X1=training_data(republican_indices,:);
%removing the labels
X0=X0(:,2:end);
X1=X1(:,2:end);

M=10
[params, weights] = boostlearn(X0.', X1.', M);

X=[X0.',X1.'];
C=boosteval(X,params,weights);

predicted_democrat_indices=find(C==1);
predicted_republican_indices=find(C==-1);

num_errors=sum(predicted_democrat_indices>216);
num_errors=num_errors+sum(predicted_republican_indices<217);
%num_errors=17
%training_accuracy=331/348=95.1%


%Observation: when we increase M, num_errors is always 17, i.e. the training
%accuracy doesn't increase with M.

%now we test our model

democrat_testing_indices=find(testing_data(:,1)==1);
republican_testing_indices=find(testing_data(:,1)==-1);
X0_testing=testing_data(democrat_testing_indices,:);
X1_testing=testing_data(republican_testing_indices,:);
%removing the labels
X0_testing=X0_testing(:,2:end);
X1_testing=X1_testing(:,2:end);

X_testing=[X0_testing.',X1_testing.'];
C_testing_labels=boosteval(X_testing,params,weights);

testing_predicted_democrat_indices=find(C_testing_labels==1);
testing_predicted_republican_indices=find(C_testing_labels==-1);

testing_num_errors=sum(testing_predicted_democrat_indices>51);
testing_num_errors=testing_num_errors+sum(testing_predicted_republican_indices<52);

%accuracy=85/87=97.7%


#---------------------------------------------------------------------------#
%plotting the decision boundary for SVM projected to the first two PCs.


votes = csvread('votes.csv'); %Creates 435 by 17 array 
t = votes(:,1); % True labels of D or R

X = votes(:, 2:end); % Data : Voting record
N = size(X,1); %435
D = size(X,2); %16

R_indices = find(t==-1);
D_indices = find(t== 1);

cov_mat = cov(X);
 [U S V] = svd(cov_mat);
 PCs = U;
 PC1 = PCs(:,1);
 PC2 = PCs(:,2);

w = [0.0762;
    0.0118;
    0.1909;
   -0.4809;
   -0.1359;
    0.0151;
   -0.0353;
    0.0447;
    0.1054;
   -0.0326;
    0.1320;
   -0.1404;
   -0.0518;
   -0.0623;
    0.0557;
   -0.0269 ];
b = 0.2675;

alpha_1=w.'*PC1;
alpha_2=w.'*PC2;

x=linspace(-4,4);
y=(-alpha_1/alpha_2)*x-b/alpha_2;


x_axis = zeros(N,1);
y_axis = zeros(N,1);
for i = 1:N
    data_point = X(i, :);
    x_axis(i) = dot(data_point, PC1);
    y_axis(i) = dot(data_point, PC2);     
end %for_loop

figure
hold on
scatter(x_axis(R_indices), y_axis(R_indices), 'r')
scatter(x_axis(D_indices), y_axis(D_indices), 'b')
title('SVM Decision Boundary Projection to the First Two Principal Components')
xlabel('1st Principal Component')
ylabel('2nd Principal Component')

plot(x,y,'LineWidth',2);
axis([-4 4 -4 4]);

hold off
#---------------------------------------------------------------------------#




#-------------------------------------------------------------------------#
%Adaboost on dimensionally reduced dataset

%first we get the principal components
votes = csvread('votes.csv'); %Creates 435 by 17 array 
X = votes(:, 2:end); % Data : Voting record
N = size(X,1); %435
D = size(X,2); %16
cov_mat = cov(X);
[U S V] = svd(cov_mat);
PCs = U;
PC1 = PCs(:,1);
PC2 = PCs(:,2);
%------------%

training_data=csvread('training_data.csv');
testing_data=csvread('testing_data.csv');

democrat_indices=find(training_data(:,1)==1);
republican_indices=find(training_data(:,1)==-1);
X0_training=training_data(democrat_indices,:);
X1_training=training_data(republican_indices,:);
%removing the labels
X0_training=X0_training(:,2:end);
X1_training=X1_training(:,2:end);

%now we project the data to the 2 components

num_training_democrats=size(X0_training,1);
num_training_republicans=size(X1_training,1);
projected_X0_training=zeros(num_training_democrats,2);
projected_X1_training=zeros(num_training_republicans,2);
for i=1:num_training_democrats
    projected_X0_training(i,1)=X0_training(i,:)*PC1;
    projected_X0_training(i,2)=X0_training(i,:)*PC2;
end

for i=1:num_training_republicans
    projected_X1_training(i,1)=X1_training(i,:)*PC1;
    projected_X1_training(i,2)=X1_training(i,:)*PC2;
end


M=10
[params, weights] = boostlearn(projected_X0_training.', projected_X1_training.', M);

X=[projected_X0_training.',projected_X1_training.'];
C=boosteval(X,params,weights);

predicted_democrat_indices=find(C==1);
predicted_republican_indices=find(C==-1);

num_errors=sum(predicted_democrat_indices>216);
num_errors=num_errors+sum(predicted_republican_indices<217);
%num_errors=21
%training_accuracy=327/348=94.0%

%------------%
%now we test our model

democrat_testing_indices=find(testing_data(:,1)==1);
republican_testing_indices=find(testing_data(:,1)==-1);
X0_testing=testing_data(democrat_testing_indices,:);
X1_testing=testing_data(republican_testing_indices,:);
%removing the labels
X0_testing=X0_testing(:,2:end);
X1_testing=X1_testing(:,2:end);



%now we project the data to the 2 components

num_testing_democrats=size(X0_testing,1);
num_testing_republicans=size(X1_testing,1);
projected_X0_testing=zeros(num_testing_democrats,2);
projected_X1_testing=zeros(num_testing_republicans,2);
for i=1:num_testing_democrats
    projected_X0_testing(i,1)=X0_testing(i,:)*PC1;
    projected_X0_testing(i,2)=X0_testing(i,:)*PC2;
end

for i=1:num_testing_republicans
    projected_X1_testing(i,1)=X1_testing(i,:)*PC1;
    projected_X1_testing(i,2)=X1_testing(i,:)*PC2;
end

X_testing=[projected_X0_testing.',projected_X1_testing.'];
C_testing_labels=boosteval(X_testing,params,weights);

testing_predicted_democrat_indices=find(C_testing_labels==1);
testing_predicted_republican_indices=find(C_testing_labels==-1);

testing_num_errors=sum(testing_predicted_democrat_indices>51);
testing_num_errors=testing_num_errors+sum(testing_predicted_republican_indices<52);

%accuracy=78/87=89.7%







 
 
 







